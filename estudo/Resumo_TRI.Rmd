---
title: "Resumo TRI"
author: "Davi Wentrick Feijó - 200016806"
date: "2023-10-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Pacotes
pacman::p_load(tidyverse,reshape2,knitr,irtoys,ltm,mirt)
```


### Teoria Clássica dos Testes

A Teoria Clássica dos Testes (TCT) é uma abordagem que visa medir traços latentes, que são características de indivíduos que nao podem se medir diretamente, como níveis de conhecimento ou depressão. Nessa teoria, a medida de proficiência de um indivíduo é baseada no escore total do teste aplicado a ele, vale notar que o escore de um indivíduo é o total de itens para os quais ele(a) forneceu resposta positiva. No entanto, a TCT apresenta limitações, incluindo a dependência da medida de proficiência em relação ao teste específico aplicado e dos parâmetros dos itens em relação ao grupo de respondentes.

A TCT envolve a análise dos itens do teste e do instrumento de medida como um todo. Ela se concentra na pontuação geral do teste como a medida do traço latente. Isso significa que diferentes testes podem levar a estimativas diferentes da proficiência de um indivíduo, mesmo que o traço latente seja o mesmo. Além disso, os parâmetros dos itens, como dificuldade e discriminação, podem variar dependendo do grupo de respondentes.

Em resumo, a TCT é uma abordagem tradicional para medir traços latentes, mas apresenta limitações relacionadas à dependência do teste específico e aos parâmetros dos itens em relação aos grupos de respondentes. 

Temos dois tipos possiveis de questoes em um teste:

+ Dicotômicos (respostas binárias, como sim ou não) 

+ Politômicos (questões de múltipla escolha, onde a escolha influencia na estimativa do traço latente). Por exemplo, em um questionário para avaliar o nível de depressão, um item poderia ser: "Você se sente triste: ( ) nunca; ( ) de vez em quando; ( ) com frequência; ( ) sempre", com as alternativas em uma escala ordinal que indica o grau crescente de depressão.

```{r echo=FALSE, warning=FALSE}
altura <- read.fwf(file="altura211.txt", widths=c(3,4,rep(1,14)),dec=',')

# insere nomes nas colunas
colnames(altura) <- c("id","altura",paste(c("i"),1:14,sep=""))

head(altura)
```

Para realizar o calculo de algumas estatisticas descritivas vamos usar a função `descript()` do pacote `ltm` que faz esse calculo usando os dados de questionario com respostas dicotomicas ou politomicas.

```{r}
altura.itens <- altura[,3:16] # utilizando apenas as colunas de respostas
altura.desc <- descript(altura.itens)
```

#### Coeficiente de correlação ponto-bisserial

O coeficiente de correlação ponto-bisserial é calculado entre a variável indicadora de respostas positivas para um item e os escores dos indivíduos. Idealmente, esperamos que todos os itens tenham valores positivos para esse coeficiente, o que indica que as respostas positivas aumentam à medida que os escores dos indivíduos aumentam.

Se um item apresentar um valor negativo para o coeficiente ponto-bisserial, isso sugere uma inconsistência entre os escores dos indivíduos e suas respostas para o item. Isso significa que o item mostra uma tendência de obter mais respostas positivas de indivíduos com escores baixos, em vez de escores altos, o que é incoerente. Nesse caso, geralmente é recomendado remover ou reformular o item, pois ele não está medindo adequadamente o traço latente que se pretende avaliar com o teste (questionário).

$$
\rho_{i}^{PB} = \left( \frac{\bar T_A - \bar T}{S_T} \right) \sqrt{\frac{P_i}{1-P_i}}
$$
Onde:

+ $\bar T$ é o escore médio dos respondentes 
+ $\bar T$ é o escore médio dos respondentes com resposta positiva (1) para o i-ésimo item
+ $S_T$ é o desvio padrao dos escores
+ $P_i$ é a proporcao de respostas positivas para o i-esimo item

```{r}
rho.PB <- altura.desc$bisCorr
```

```{r echo=FALSE}
rho.PB
```



#### Coeficiente de correlação bisserial

O coeficiente de correlação bisserial é uma medida de associação entre uma
variável dicotomizada e uma variável contínua (não observada) associada ao
construto (traço latente). Tem a mesma interpretação da correlação ponto-bisserial.

```{r}
# correlação bisserial
rho.B.vec <- rep(0,14)

for (i in 1:14) {
  pp <- colSums(altura.itens)[i]/nrow(altura.itens)
  rho.B <- sqrt(pp*(1-pp))*altura.desc$bisCorr[i]/dnorm(qnorm(pp,0,1),0,1)
  rho.B.vec[i] <- rho.B
}
```

Vamos montar uma tabela com os resultados do ponto-bisserial e bisserial

```{r echo=FALSE}
kable(data.frame(rho.PB, rho.B.vec), 
      col.names = c("Ponto-bisserial", "Bisserial"), align = "c")
```

#### Alfa de Cronbach

O coeficiente \alfa de Cronbach é usado para avaliar a consistência interna de um instrumento de medida, com valores normalmente variando de 0 a 1. Um valor mínimo aceitável para \alfa é 0,70, indicando que a consistência interna dos itens é considerada baixa se estiver abaixo desse limite. O valor 1-pi pode ser usado como um índice de dificuldade do item.

$$
\alpha = \frac{I}{I-1} \left( 1- \frac{\sum_{i=1}^{I} S^2_i}{S^2_T} \right)
$$

+ $S^2_i$ é a variancia das respostas para o i-ésimo item

+ $S_T$ é o desvio padrao dos escores

```{r}
cronbach.alpha(altura.itens)
```

##### Indice de dificuldade do item:

É o calculo do total de respostas positivas por item dividido pelo total de respondentes, que vai ser a probabilidade de acerto, menos 1 que nao dara o numero de erros ou resposta negativa.

```{r}
(1-apply(altura.itens,2,sum)/nrow(altura.itens))
```


##### Índice de Discriminação do Item

Além disso, na Teoria Clássica dos Testes (TCT), há o Índice de Discriminação do Item, que é calculado pela diferença entre a proporção de respostas positivas para o item no grupo superior (27% dos respondentes com os escores mais altos) e a proporção no grupo inferior (27% dos respondentes com os escores mais baixos), variando de -1 a 1. Isso ajuda a entender como o item diferencia entre os grupos de desempenho.

```{r}
escore <- apply(altura.itens,1,sum)
aux <- ceiling(0.27*nrow(altura.itens))
escore.inf <- sort(escore)[aux]
escore.sup <- sort(escore)[nrow(altura.itens)-aux]

altura.inf <- altura.itens[escore<=escore.inf,]
altura.sup <- altura.itens[escore>=escore.sup,]

apply(altura.sup,2,sum)/nrow(altura.sup)-apply(altura.inf,2,sum)/nrow(altura.inf)
```


Por fim, menciona-se o erro padrão de medida, que é uma medida de precisão do teste, indicando o quão confiavelmente o teste mede o traço latente que se pretende avaliar.


$$
EPM = S_t \sqrt{1-\alpha} \approx S_t \sqrt{\sum_{i=1}^{i}P_i(1-P_i)}
$$

### Teoria de Resposta ao Item

Na tabela abaixo, estao apresentados os parametros dos itens para dois testes distintos, cada um com 6 itens.

```{r echo=FALSE}
mat.par.1 <- data.frame("a" = c(1.8, .7, 1.8, 1.2, 1.2, .5),
                        "b" = c(1, 1, 1, -.5, .5, 0),
                        "c" = c(0.2, 0.2, .25, .2, 0.25, .25))
mat.par.2 <- data.frame("a" = c(2, .5, 1.5, 1.3, 1.1, .7), 
                        "b" = c(-1, 1, -1.5, .5, 1.5, 2), 
                        "c" = c(0.2, 0.2, .25, .2, 0.25, .25))
theta <- seq(-4,4,0.01)

mat.prob1 <- mat.prob2 <- data.frame(theta)
head(mat.par.1)
head(mat.par.2)
```


#### Modelo logistico de um parametro (ML1)


$$
P(U_{ij} = 1|\theta_j) = \frac{1}{1+e^{-(\theta-b_i)}}
$$

+ $b_i$ é o parametro de dificuldade do i-ésimo item

+ $\theta_j$ é a proficiencia do j-esimo respondente


#### Modelo logistico de um parametro (ML2)

$$
P(U_{ij} = 1|\theta_j) = \frac{1}{1+e^{-a_i(\theta-b_i)}}
$$

+ $a_i$ é o parametro de discriminacao do item

O valor de $a_i$ está relacionado diretamente à inclinação da "curva característica do item" (CCI), que descreve a probabilidade de uma resposta positiva $P(U_{ij} = 1|\theta_j)$ em relação a um parâmetro de habilidade $\theta_j$. Quanto maior o valor de $a_i$, maior é a inclinação da curva. Isso significa que há uma diferença mais acentuada nas probabilidades de resposta positiva entre dois indivíduos, um com habilidade acima do parâmetro de dificuldade $b_i$ e outro com habilidade abaixo de $b_i$. Em outras palavras, um maior valor de $a_i$ indica uma capacidade maior do item em distinguir entre indivíduos com habilidades significativamente diferentes em relação ao parâmetro de dificuldade do item.

#### Modelo logistico de um parametro (ML3)

$$
P(U_{ij} = 1|\theta_j) = c_i + \frac{1-c_i}{1+e^{-a_i(\theta-b_i)}}
$$

+ $c_i$ é o parâmetro de acerto ao acaso

Neste modelo, é introduzido um terceiro parâmetro do item chamado "parâmetro de acerto ao acaso" ($c_i$). Esse modelo é aplicado especificamente quando o traço latente a ser estimado é o "conhecimento". O termo "acerto ao acaso" deriva do fato de que a probabilidade de uma resposta positiva $P(U_{ij} = 1|\theta_j)$ é igual a $c_i$ quando a habilidade latente ($\theta_j$) tende ao infinito negativo. Mesmo quando o indivíduo possui habilidade muito baixa, a probabilidade de dar uma resposta positiva para o item permanece igual a $c_i$. Vale ressaltar que $c_i$ é uma probabilidade e, portanto, está restrita ao intervalo de 0 a 1.


Para nosso exemplo, a nossa base de dados contem os $a_i$,$b_i$ e $c_i$, logo usaremos o ML3 para montar nossas CCI.

```{r}
# Gráfico das CCI"s para o teste 1 

for (i in 1:nrow(mat.par.1)) {
  mat.prob1[paste("i", i, sep = "")] <-  mat.par.1$c[i] + (1-mat.par.1$c[i])/
    (1+exp(-mat.par.1$a[i]*(theta-mat.par.1$b[i])))
}

# Gráfico das CCI"s para o teste 2

for (i in 1:nrow(mat.par.2)) {
  mat.prob2[paste("i", i, sep = "")] <-  mat.par.2$c[i] + (1-mat.par.2$c[i])/
    (1+exp(-mat.par.2$a[i]*(theta-mat.par.2$b[i])))
}
```


```{r echo=FALSE}
mat.prob1$teste <- "Teste 1"
mat.prob2$teste <- "Teste 2"

rbind(mat.prob1, mat.prob2) %>% 
  melt(id.vars = c("theta", "teste")) %>%
  ggplot(aes(theta, value, color = variable)) + geom_line() +
  facet_wrap(~teste) +
  labs(color = "Item") + theme_bw()
```


#### Informacao de Fisher (para o traco latente)

Sob condições regulares, o estimador de máxima verossimilhança de $\theta_j$ segue uma distribuição aproximadamente normal com média $\theta_j$ e variância inversamente proporcional à informação de Fisher. Portanto, ao analisar a informação de fisher em funcao de \theta, podemos determinar os valores de proficiência para os quais a estimativa é mais precisa, o que ocorre quando a informação é maior. Em resumo, a precisão da estimativa de $\theta_j$ é influenciada pela informação disponível e ela estima melhor em valores de proficiência (\theta) onde a curva da informação de fisher apresenta valores mais altos.

$$
I_i(\theta) = \frac{[P'(\theta)]^2}{P(\theta)(1-P(\theta))}
$$
onde :

$$
P'(\theta) = \frac{a_i(1-c_i)e^{-a_i(\theta-b_i)}}{[1+e^{-a_i(\theta-b_i)}]^2}
$$

```{r}

mat.prob <- mat.prob.dif <- mat.info <- matrix(0,nrow(mat.par.1),length(theta))

for (i in 1:nrow(mat.par.1)) {
  for (j in 1:length(theta)) {
    mat.prob[i,j] <- mat.par.1[i,3] + (1-mat.par.1[i,3])/(1+exp(-mat.par.1[i,1]*(theta[j]-mat.par.1[i,2]))) #p(theta)
    mat.prob.dif[i,j] <- mat.par.1[i,1]*(1-mat.par.1[i,3])*exp(-mat.par.1[i,1]*(theta[j]-mat.par.1[i,2]))/ #p'(theta)
      ((1+exp(-mat.par.1[i,1]*(theta[j]-mat.par.1[i,2])))^2)
    mat.info[i,j] <- (mat.prob.dif[i,j]^2)/(mat.prob[i,j]*(1-mat.prob[i,j]))
  }
}

info.1 <- apply(mat.info,2,sum)

plot(theta,info.1,type="l")

for (i in 1:nrow(mat.par.2)) {
  for (j in 1:length(theta)) {
    mat.prob[i,j] <- mat.par.2[i,3] + (1-mat.par.2[i,3])/(1+exp(-mat.par.2[i,1]*(theta[j]-mat.par.2[i,2])))
    mat.prob.dif[i,j] <- mat.par.2[i,1]*(1-mat.par.2[i,3])*exp(-mat.par.2[i,1]*(theta[j]-mat.par.2[i,2]))/
      ((1+exp(-mat.par.2[i,1]*(theta[j]-mat.par.2[i,2])))^2)
    mat.info[i,j] <- (mat.prob.dif[i,j]^2)/(mat.prob[i,j]*(1-mat.prob[i,j]))
  }
}

info.2 <- apply(mat.info,2,sum)

lines(theta,info.2,lty=2)
legend(-4,1.5,c("Teste 1", "Teste 2"), lty=c(1,2))
```

Podemos notar que o teste 1 estima melhor as proficiencias no intervalo [-2,0] enquanto que o teste 2 no intervalo [0,2]. Podemos saber disso pois sao os intervalos que concentram o ponto de maximo da curva.

#### Item Ancora


Para um item ser considerado uma âncora em um determinado nível da escala, ele deve atender simultaneamente a três condições:

+ $P(U = 1 | θ = Z) ≥ 0.65$: Deve ser respondido corretamente por pelo menos 65% dos indivíduos com esse nível de habilidade (θ = Z).

+ $P(U = 1 | θ = Y ) < 0.50$: Não deve ser respondido corretamente por mais de 50% dos indivíduos com o nível de habilidade imediatamente anterior (θ = Y).

+ $P(U = 1 | θ = Z) − P(U = 1 | θ = Y ) ≥ 0.30$: A diferença entre a proporção de indivíduos com esses níveis de habilidade que acertam o item deve ser pelo menos 30%.

Em resumo, um item âncora é um item típico daquele nível de habilidade, sendo amplamente acertado por pessoas com esse nível de habilidade, mas pouco acertado por pessoas com um nível de habilidade imediatamente inferior.

Nesse exemplo vamos estar interessando em saber se tem algum item ancora no nivel 1 de proficiencia (\theta) e vamos comparar com o nivel -1 para assim ver se atendemos esses requisitos.

```{r}
theta.Z <- 1
theta.Y <- -1

t1 <- t2 <- data.frame("i" = 1:6)

t1$p.Z <- mat.par.1$c + (1-mat.par.1$c)/(1+exp(-mat.par.1$a*(theta.Z-mat.par.1$b))) #condicao 1
t1$p.Y <- mat.par.1$c + (1-mat.par.1$c)/(1+exp(-mat.par.1$a*(theta.Y-mat.par.1$b))) #condicao 2
t1$dif <- t1$p.Z - t1$p.Y #condicao 3

t2$p.Z <- mat.par.2$c + (1-mat.par.2$c)/(1+exp(-mat.par.2$a*(theta.Z-mat.par.2$b))) #condicao 1
t2$p.Y <- mat.par.2$c + (1-mat.par.2$c)/(1+exp(-mat.par.2$a*(theta.Y-mat.par.2$b))) #condicao 2
t2$dif <- t2$p.Z - t2$p.Y #condicao 3
```


```{r echo=FALSE}
kable(t1, align = "c", col.names = c("Item", "p.Z", "p.Y", "Dif"))

kable(t2, align = "c", col.names = c("Item", "p.Z", "p.Y", "Dif"))
```

```{r}
ancoras_t1 <- t1 %>%
  filter(p.Z >= 0.65, p.Y < 0.5, dif >= 0.3)

ancoras_t2 <- t2 %>%
  filter(p.Z >= 0.65, p.Y < 0.5, dif >= 0.3)
```


```{r echo=FALSE}
# Exibir o resultado
print(ancoras_t1)
print(ancoras_t2)
```


